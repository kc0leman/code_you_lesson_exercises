{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae203d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Columns and Rows\n",
    "# Sometimes, your dataset includes extra information you don’t need — columns that are irrelevant to your goals, or rows that are incomplete or duplicated. Cleaning up your data often starts with dropping the parts you don’t want.\n",
    "\n",
    "# In Pandas, the .drop() method is your main tool for this. Here are the syntax basics:\n",
    "\n",
    "# # Drop a column\n",
    "# df = df.drop('column_name', axis=1)\n",
    "\n",
    "# # Drop multiple columns\n",
    "# df = df.drop(['col1', 'col2'], axis=1)\n",
    "\n",
    "# # Drop a row by index\n",
    "# df = df.drop(0)\n",
    "\n",
    "# # Drop rows with missing values\n",
    "# df = df.dropna()\n",
    "\n",
    "\n",
    "# Note:\n",
    "# axis=0 means rows\n",
    "# axis=1 means columns\n",
    "# By default, .drop() returns a new DataFrame unless you use inplace=True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why Drop Columns or Rows?\n",
    "# Columns might be completely irrelevant to your analysis (e.g., “ID” or “notes” fields)\n",
    "# Rows might be testing data, error logs, or outliers\n",
    "# You may need to eliminate incomplete records with missing critical values\n",
    "# Sometimes you'll filter out rows temporarily to check something — .drop() is one way to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6010dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples:\n",
    "\n",
    "# # Drop a single column\n",
    "# df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# # Drop multiple columns\n",
    "# df = df.drop(['email', 'phone'], axis=1)\n",
    "\n",
    "# # Drop a row by index (e.g., row 5)\n",
    "# df = df.drop(5, axis=0)\n",
    "\n",
    "# # Drop rows 0 through 3\n",
    "# df = df.drop([0, 1, 2, 3], axis=0)\n",
    "# You can also drop in place, which means that the DataFrame is modified without having to save it by typing in 'df =' first:\n",
    "\n",
    "# df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4b3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Mistakes to Watch Out For\n",
    "# Forgetting axis=1 when dropping columns (the default is axis=0, so it tries to drop a row instead)\n",
    "# Not assigning the result back to df (unless using inplace=True)\n",
    "# Dropping rows by label when your index isn't numeric (consider using .reset_index() first if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b514d648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age     City\n",
      "0    Alice   25      NYC\n",
      "1      Bob   30       LA\n",
      "2  Charlie   35  Chicago\n",
      "3    David   40    Miami\n",
      "    Name  Age   City          Email\n",
      "0  Alice   25    NYC  a@example.com\n",
      "1    Bob   30     LA  b@example.com\n",
      "3  David   40  Miami  d@example.com\n",
      "      Name  Age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n",
      "3    David   40\n"
     ]
    }
   ],
   "source": [
    "# Practice Dropping Rows and Columns\n",
    "\n",
    "\n",
    "# Leave the following code, it will import pandas and create a sample dataframe.\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Miami'],\n",
    "    'Email': ['a@example.com', 'b@example.com', 'c@example.com', 'd@example.com']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# 1. Drop the Email column and store in new variable\n",
    "df_no_email = df.drop('Email', axis=1)\n",
    "print(df_no_email)\n",
    "\n",
    "# 2. Drop row with index 2 in place\n",
    "df.drop(2, axis=0, inplace=True)\n",
    "print(df)\n",
    "\n",
    "# Re-create DataFrame for next steps- just leave this alone\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 3. Drop City and Email columns, assign back to df\n",
    "df = df.drop(['City', 'Email'], axis=1)\n",
    "print(df)\n",
    "\n",
    "# Re-create again for next step\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 4. Drop first and last row, store in df_trimmed\n",
    "df_trimmed = df.drop([df.index[0], df.index[-1]])\n",
    "# print(df_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2dabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Values\n",
    "\n",
    "# Sometimes, the data you're working with has placeholder or incorrect values — like \"N/A\", \"?\", \"none\", or \"missing\" instead of actual nulls (NaN). Other times, values are simply mislabeled or need to be standardized (e.g., \"yes\" and \"Yes\" should be treated the same).\n",
    "# The .replace() method in Pandas is a quick and flexible way to update those values.\n",
    "\n",
    "# Here is the basic syntax:\n",
    "# df['column_name'].replace(to_replace, value)\n",
    "# You can replace a single value, multiple values (using a dictionary), or across the entire DataFrame. See the following examples:\n",
    "\n",
    "# df['Gender'].replace('M', 'Male') # Replaces a single value\n",
    "# df['Gender'].replace({'M': 'Male', 'F': 'Female'}) # Replaces multiple values\n",
    "# df.replace('?', np.nan) # Replaces all ? in the DataFrame with NaN\n",
    "# Pro tip: Replacing is often a first step before handling missing values — for example, converting \"N/A\" or -1 into np.nan so you can later drop or fill those values cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "\n",
    "# In the real world, data is rarely perfect. It's common to have missing or incomplete values in your dataset. These could be empty cells in a spreadsheet, null entries in a database, or NaN (Not a Number) values in a DataFrame.\n",
    "# Missing values matter because they can break your analysis or skew results — especially if they exist in important columns you're trying to calculate things on.\n",
    "\n",
    "\n",
    "# How do we detect missing values in pandas?\n",
    "# df.isnull() # Returns a DataFrame of True/False values showing where data is missing\n",
    "# But an easier way to view it is by summing the values of True:\n",
    "# df.isnull().sum() # This will tell you how many missing values are in each column.\n",
    "\n",
    "\n",
    "# How do we handle missing values?\n",
    "# There are a few common strategies:\n",
    "\n",
    "# 1. Drop rows or columns with missing values\n",
    "# df.dropna()\n",
    "# By default, drops any row with at least one missing value. If you want to drop an entire column with any missing values, set axis = 1:\n",
    "# df.dropna(axis=1)\n",
    "\n",
    "\n",
    "# 2. Fill missing values with something else\n",
    "# df.fillna(0)                      # Replace missing values with 0\n",
    "# df.fillna('Unknown')             # Replace missing strings with a placeholder\n",
    "# df.fillna(df['Age'].mean())      # Replace with the column mean (or median, or mode)\n",
    "\n",
    "\n",
    "# Best Practices\n",
    "# There’s no one-size-fits-all answer - your approach depends on how much is missing and what kind of analysis you're doing. But here are some helpful guidelines:\n",
    "# Drop the column if it's mostly missing and not essential\n",
    "# Drop the row if it’s just a few and you have enough data\n",
    "# Fill in the value if it’s just missing a little and you can justify what to use\n",
    "\n",
    "\n",
    "# Common fill strategies:\n",
    "# Use the mean or median for numbers\n",
    "# Use the most common value for categories\n",
    "# Use \"Unknown\" or \"Not Provided\" for missing strings\n",
    "# Use 0 or a flag like False for missing booleans\n",
    "# Try not to overthink it - missing values are extremely common in real-world data. But use caution: how you handle them can significantly impact your results. Always consider why the data might be missing and what your end goals are.\n",
    "# The approach you take should make sense for your context, and be something you can clearly explain later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice Handling Missing Data\n",
    "\n",
    "\n",
    "# Leave this code alone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Age': [25, np.nan, 35, 40, None],\n",
    "    'City': ['NYC', 'LA', None, 'Miami', 'Boston']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Answer the questions below!\n",
    "# 1. View the DataFrame\n",
    "print(df)\n",
    "\n",
    "# 2. Show where values are missing\n",
    "print(df.isnull())\n",
    "\n",
    "# 3. Count of missing values by column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 4. Drop rows with missing data\n",
    "print(df.dropna())\n",
    "\n",
    "# 5. Re-create original - leave this part alone\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 6. Drop columns with missing data\n",
    "print(df.dropna(axis=1))\n",
    "\n",
    "# 7. Re-create again - Leave this alone again\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 8. Fill missing Age with mean\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "print(df)\n",
    "\n",
    "# 9. Fill missing City with \"Unknown\"\n",
    "df['City'] = df['City'].fillna('Unknown')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Data Types\n",
    "# When you load in a dataset, the column data types (called dtypes in pandas) don’t always come in the way you expect. Maybe a column full of numbers gets read as strings, or a column with dates stays as plain text. If you don’t catch these issues early, they can quietly cause bugs or errors later in your analysis.\n",
    "\n",
    "# To view the current data types of your columns, use:\n",
    "# df.dtypes\n",
    "# Or, as you remember from the last lesson, the data types are shown when using df.info()\n",
    "\n",
    "\n",
    "# Why Data Types Matter\n",
    "# Data types affect what you can do with each column. For example:\n",
    "\n",
    "# You can’t calculate a mean on a column of strings, even if they look like numbers.\n",
    "# You can’t filter by date unless pandas knows it’s a datetime object.\n",
    "# You might waste memory or processing time using a float64 column that only holds integers from 1–5.\n",
    "\n",
    "\n",
    "# Common Fixes with .astype()\n",
    "# To change a column’s data type, use:\n",
    "\n",
    "# df['ColumnName'] = df['ColumnName'].astype(new_type)\n",
    "# Here are some common examples:\n",
    "\n",
    "# # Convert numeric strings to actual numbers\n",
    "# df['Revenue'] = df['Revenue'].astype(float)\n",
    "\n",
    "# # Convert integers to strings (e.g., zip codes)\n",
    "# df['ZipCode'] = df['ZipCode'].astype(str)\n",
    "\n",
    "# # Convert float to integer (use with caution)\n",
    "# df['Quantity'] = df['Quantity'].astype(int)\n",
    "# Note: Converting from float to int will drop decimal values (not round!), so make sure that makes sense for your context.\n",
    "\n",
    "\n",
    "# Dates Require Special Handling\n",
    "# To convert a column to datetime format (so you can do time-based filtering or aggregation), use:\n",
    "\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "# Pandas is smart about most common date formats, but if it doesn’t work automatically, you can provide a format string like this:\n",
    "\n",
    "# df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
    "# You’ll learn more about working with dates in the data wrangling module — for now, just know that this is how you convert plain text to actual dates.\n",
    "\n",
    "\n",
    "# Best Practices\n",
    "# Always check df.dtypes and df.info() right after loading your data.\n",
    "# Be intentional: only convert types if you’re confident in what they should be.\n",
    "# If you’re unsure whether something is numeric or not, try using .astype(float) in a test cell and see if it throws an error — it’s often faster than overthinking it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Duplicates\n",
    "# Sometimes, your dataset includes rows that are exact copies of one another - either due to data entry errors, accidental merges, or export quirks. These duplicate rows can skew your analysis, inflate counts, or create confusion if not handled properly.\n",
    "# Luckily, Pandas makes it easy to check for and remove duplicates using:\n",
    "\n",
    "# .duplicated() — returns a Boolean Series indicating if a row is a duplicate of a previous one\n",
    "# .drop_duplicates() — returns a new DataFrame with duplicates removed\n",
    "\n",
    "# Example:\n",
    "# import pandas as pd\n",
    "# # Sample data\n",
    "# data = {\n",
    "#     'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob'],\n",
    "#     'Age': [25, 30, 35, 25, 30]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "# print(df)\n",
    "\n",
    "# Output:\n",
    "\n",
    "#       Name  Age\n",
    "# 0    Alice   25\n",
    "# 1      Bob   30\n",
    "# 2  Charlie   35\n",
    "# 3    Alice   25\n",
    "# 4      Bob   30\n",
    "\n",
    "# We can clearly see that rows 0 and 3 are identical, and so are rows 1 and 4, but what about when it isn't so obvious?\n",
    "\n",
    "\n",
    "# How to Find and Remove Duplicates\n",
    "# # Check which rows are duplicates (compares to earlier rows)\n",
    "# df.duplicated()\n",
    "\n",
    "# # Drop duplicates (keeps first occurrence by default)\n",
    "# df_cleaned = df.drop_duplicates()\n",
    "\n",
    "\n",
    "# Optional Arguments for drop_duplicates()\n",
    "# keep='first' (default): keeps the first occurrence, drops the rest\n",
    "# keep='last': keeps the last occurrence\n",
    "# keep=False: drops all duplicates\n",
    "# You can also specify a subset of columns to check for duplicates:\n",
    "\n",
    "# # Only consider 'Name' column when looking for duplicates\n",
    "# df.drop_duplicates(subset='Name')\n",
    "\n",
    "\n",
    "# Best Practice Tips\n",
    "# Use .duplicated() before .drop_duplicates() so you understand what you're removing.\n",
    "# Think carefully before dropping duplicates — sometimes they’re valid!\n",
    "# If you're only concerned about certain columns (e.g., name/email duplicates), use the subset parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice removing duplicates\n",
    "\n",
    "\n",
    "# LEAVE THIS CODE ALONE\n",
    "import pandas as pd\n",
    "\n",
    "# Load sample data\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob', 'Diana'],\n",
    "    'Age': [25, 30, 35, 25, 30, 40],\n",
    "    'City': ['NYC', 'LA', 'SF', 'NYC', 'LA', 'NYC']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ANSWER THE FOLLOWING QUESTIONS\n",
    "\n",
    "# 1. Find which rows are duplicates (across all columns)\n",
    "print(\"\\nDuplicated rows (True if row is a duplicate of an earlier one):\")\n",
    "print(df.duplicated())\n",
    "\n",
    "# 2. Drop duplicate rows (keeping the first occurrence)\n",
    "print(\"\\nDataFrame with duplicates dropped (keep='first'):\")\n",
    "print(df.drop_duplicates())\n",
    "\n",
    "# 3. Drop duplicate rows (keeping only the last occurrence)\n",
    "print(\"\\nDataFrame with duplicates dropped (keep='last'):\")\n",
    "print(df.drop_duplicates(keep='last'))\n",
    "\n",
    "# 4. Drop ALL duplicates (remove both original and duplicate)\n",
    "print(\"\\nDataFrame with ALL duplicates removed (keep=False):\")\n",
    "print(df.drop_duplicates(keep=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
